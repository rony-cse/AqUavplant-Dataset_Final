{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-18T08:50:57.176352Z",
     "iopub.status.busy": "2024-05-18T08:50:57.175576Z",
     "iopub.status.idle": "2024-05-18T08:50:57.182465Z",
     "shell.execute_reply": "2024-05-18T08:50:57.181471Z",
     "shell.execute_reply.started": "2024-05-18T08:50:57.176321Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import os\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import scipy.io\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "\n",
    "BATCH_SIZE = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AqUavplant dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T08:50:59.296687Z",
     "iopub.status.busy": "2024-05-18T08:50:59.296254Z",
     "iopub.status.idle": "2024-05-18T08:51:00.126051Z",
     "shell.execute_reply": "2024-05-18T08:51:00.125082Z",
     "shell.execute_reply.started": "2024-05-18T08:50:59.296659Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_numerical_part(string):\n",
    "    # Use regex to find numerical part in the string\n",
    "    numerical_part = re.findall(r'\\d+', string)[0]\n",
    "    return numerical_part\n",
    "\n",
    "\n",
    "class aquatic_plant_dataset:\n",
    "    def __init__(self, imagePaths, transforms, mode, img_target_shape = 512):\n",
    "        # store the image and mask filepaths, and augmentation\n",
    "        self.imagePaths = imagePaths\n",
    "        #self.maskPaths = maskPaths\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "        self.train_list = []\n",
    "        self.val_list = []\n",
    "        self.test_list = []\n",
    "        self.target_shape = (img_target_shape, img_target_shape)\n",
    "        \n",
    "        if(self.mode == 'train'):\n",
    "            root_dir = self.imagePaths\n",
    "            # Walk through all directories and subdirectories\n",
    "            for root, dirs, files in os.walk(self.imagePaths):\n",
    "                for directory in dirs:\n",
    "                    if('frame' in directory):\n",
    "                        self.train_list.append(os.path.join(root, directory))\n",
    "        \n",
    "        elif(self.mode == 'val'):\n",
    "            # Walk through all directories and subdirectories\n",
    "            for root, dirs, files in os.walk(self.imagePaths):\n",
    "                for directory in dirs:\n",
    "                    if('frame' in directory):\n",
    "                        self.val_list.append(os.path.join(root, directory))\n",
    "                        \n",
    "        else:\n",
    "            # Walk through all directories and subdirectories\n",
    "            for root, dirs, files in os.walk(self.imagePaths):\n",
    "                for directory in dirs:\n",
    "                    if('frame' in directory):\n",
    "                        self.test_list.append(os.path.join(root, directory))\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        if(self.mode == 'train'):\n",
    "            return len(self.train_list)\n",
    "        elif(self.mode == 'val'):\n",
    "            return len(self.val_list)\n",
    "        else:\n",
    "            return len(self.test_list)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        if(self.mode == 'train'):\n",
    "            folder_dir = self.train_list[idx]\n",
    "            frame_name = folder_dir.split('/')[-1]\n",
    "            loc_name = folder_dir.split('/')[-2]\n",
    "            numeral = find_numerical_part(frame_name)\n",
    "            image_path = os.path.join(folder_dir, f'{loc_name}_{numeral}_binary.png')  \n",
    "            binary_mask = cv2.imread(image_path)  ##reading raw image\n",
    "            binary_mask = cv2.cvtColor(binary_mask, cv2.COLOR_BGR2GRAY)\n",
    "            #print(image_path)\n",
    "            \n",
    "            raw_path = os.path.join(folder_dir, f'frame_{numeral}.jpg')  ##reading the raw file\n",
    "            raw_img = cv2.imread(raw_path)  ##reading raw image\n",
    "            #print(folder_dir, raw_path)\n",
    "            #print(raw_img.shape)\n",
    "        \n",
    "        elif(self.mode == 'val'):\n",
    "            folder_dir = self.val_list[idx]\n",
    "            frame_name = folder_dir.split('/')[-1]\n",
    "            loc_name = folder_dir.split('/')[-2]\n",
    "            numeral = find_numerical_part(frame_name)\n",
    "            image_path = os.path.join(folder_dir, f'{loc_name}_{numeral}_binary.png')  \n",
    "            binary_mask = cv2.imread(image_path)  ##reading raw image\n",
    "            binary_mask = cv2.cvtColor(binary_mask, cv2.COLOR_BGR2GRAY)\n",
    "            #binary_mask = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            raw_path = os.path.join(folder_dir, f'frame_{numeral}.jpg')  ##reading the raw file\n",
    "            raw_img = cv2.imread(raw_path)  ##reading raw image\n",
    "        \n",
    "        else:\n",
    "            folder_dir = self.test_list[idx]\n",
    "            frame_name = folder_dir.split('/')[-1]\n",
    "            loc_name = folder_dir.split('/')[-2]\n",
    "            numeral = find_numerical_part(frame_name)\n",
    "            image_path = os.path.join(folder_dir, f'{loc_name}_{numeral}_binary.png')  \n",
    "            binary_mask = cv2.imread(image_path)  ##reading raw image\n",
    "            binary_mask = cv2.cvtColor(binary_mask, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            #binary_mask = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            raw_path = os.path.join(folder_dir, f'frame_{numeral}.jpg')  ##reading the raw file\n",
    "            raw_img = cv2.imread(raw_path)  ##reading raw image\n",
    "        \n",
    "        if(self.transforms is not None):\n",
    "            target_size = self.target_shape\n",
    "            raw_img = cv2.resize(raw_img, target_size)\n",
    "            binary_mask = cv2.resize(binary_mask, target_size)\n",
    "\n",
    "            \n",
    "        raw_img = np.transpose(raw_img, axes=(2, 0, 1))\n",
    "        binary_mask = np.expand_dims(binary_mask, axis=0)\n",
    "        #binary_mask = np.transpose(binary_mask, axes=(2, 0, 1))\n",
    "        \n",
    "        return torch.from_numpy(raw_img),torch.from_numpy(binary_mask)\n",
    "              \n",
    "        \n",
    "train_dataset = aquatic_plant_dataset('../input/final-run/Stratified_split/Train', True, 'train')\n",
    "val_dataset = aquatic_plant_dataset('../input/final-run/Stratified_split/Validation', True, 'val')\n",
    "test_dataset = aquatic_plant_dataset('../input/final-run/Stratified_split/Test', True, 'test')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE, num_workers = 0)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = BATCH_SIZE, num_workers = 0)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 1, num_workers = 0)   ##in testset batchsize is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T08:51:00.128444Z",
     "iopub.status.busy": "2024-05-18T08:51:00.127822Z",
     "iopub.status.idle": "2024-05-18T08:51:00.189437Z",
     "shell.execute_reply": "2024-05-18T08:51:00.188530Z",
     "shell.execute_reply.started": "2024-05-18T08:51:00.128412Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/LeeJunHyun/Image_Segmentation/blob/master/network.py\n",
    "\n",
    "# Different models (Choose any one from the five and uncomment that block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T08:51:01.250956Z",
     "iopub.status.busy": "2024-05-18T08:51:01.250531Z",
     "iopub.status.idle": "2024-05-18T08:51:01.421481Z",
     "shell.execute_reply": "2024-05-18T08:51:01.420484Z",
     "shell.execute_reply.started": "2024-05-18T08:51:01.250920Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "\n",
    "def init_weights(net, init_type='normal', gain=0.02):\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            if init_type == 'normal':\n",
    "                init.normal_(m.weight.data, 0.0, gain)\n",
    "            elif init_type == 'xavier':\n",
    "                init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init_type == 'kaiming':\n",
    "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                init.orthogonal_(m.weight.data, gain=gain)\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find('BatchNorm2d') != -1:\n",
    "            init.normal_(m.weight.data, 1.0, gain)\n",
    "            init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    print('initialize network with %s' % init_type)\n",
    "    net.apply(init_func)\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out):\n",
    "        super(conv_block,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch_out, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class up_conv(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out):\n",
    "        super(up_conv,self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n",
    "\t\t    nn.BatchNorm2d(ch_out),\n",
    "\t\t\tnn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.up(x)\n",
    "        return x\n",
    "\n",
    "class Recurrent_block(nn.Module):\n",
    "    def __init__(self,ch_out,t=2):\n",
    "        super(Recurrent_block,self).__init__()\n",
    "        self.t = t\n",
    "        self.ch_out = ch_out\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_out,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n",
    "\t\t    nn.BatchNorm2d(ch_out),\n",
    "\t\t\tnn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        for i in range(self.t):\n",
    "\n",
    "            if i==0:\n",
    "                x1 = self.conv(x)\n",
    "            \n",
    "            x1 = self.conv(x+x1)\n",
    "        return x1\n",
    "        \n",
    "class RRCNN_block(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out,t=2):\n",
    "        super(RRCNN_block,self).__init__()\n",
    "        self.RCNN = nn.Sequential(\n",
    "            Recurrent_block(ch_out,t=t),\n",
    "            Recurrent_block(ch_out,t=t)\n",
    "        )\n",
    "        self.Conv_1x1 = nn.Conv2d(ch_in,ch_out,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.Conv_1x1(x)\n",
    "        x1 = self.RCNN(x)\n",
    "        return x+x1\n",
    "\n",
    "\n",
    "class single_conv(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out):\n",
    "        super(single_conv,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class Attention_block(nn.Module):\n",
    "    def __init__(self,F_g,F_l,F_int):\n",
    "        super(Attention_block,self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "            )\n",
    "        \n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self,g,x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1+x1)\n",
    "        psi = self.psi(psi)\n",
    "\n",
    "        return x*psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U_Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-05-14T17:52:04.473103Z",
     "iopub.status.busy": "2024-05-14T17:52:04.472732Z",
     "iopub.status.idle": "2024-05-14T17:52:04.481960Z",
     "shell.execute_reply": "2024-05-14T17:52:04.481079Z",
     "shell.execute_reply.started": "2024-05-14T17:52:04.473062Z"
    }
   },
   "outputs": [],
   "source": [
    "# class U_Net(nn.Module):\n",
    "#     def __init__(self,img_ch=3,output_ch=1):\n",
    "#         super(U_Net,self).__init__()\n",
    "        \n",
    "#         self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "#         self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n",
    "#         self.Conv2 = conv_block(ch_in=64,ch_out=128)\n",
    "#         self.Conv3 = conv_block(ch_in=128,ch_out=256)\n",
    "#         self.Conv4 = conv_block(ch_in=256,ch_out=512)\n",
    "#         self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n",
    "\n",
    "#         self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "#         self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
    "\n",
    "#         self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "#         self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
    "        \n",
    "#         self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "#         self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
    "        \n",
    "#         self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "#         self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
    "\n",
    "#         self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "\n",
    "#     def forward(self,x):\n",
    "#         # encoding path\n",
    "#         x1 = self.Conv1(x)\n",
    "#         x2 = self.Maxpool(x1)\n",
    "#         x2 = self.Conv2(x2)\n",
    "#         x3 = self.Maxpool(x2)\n",
    "#         x3 = self.Conv3(x3)\n",
    "#         x4 = self.Maxpool(x3)\n",
    "#         x4 = self.Conv4(x4)\n",
    "#         x5 = self.Maxpool(x4)\n",
    "#         x5 = self.Conv5(x5)\n",
    "\n",
    "#         # decoding + concat path\n",
    "#         d5 = self.Up5(x5)\n",
    "#         d5 = torch.cat((x4,d5),dim=1)\n",
    "        \n",
    "#         d5 = self.Up_conv5(d5)\n",
    "        \n",
    "#         d4 = self.Up4(d5)\n",
    "#         d4 = torch.cat((x3,d4),dim=1)\n",
    "#         d4 = self.Up_conv4(d4)\n",
    "\n",
    "#         d3 = self.Up3(d4)\n",
    "#         d3 = torch.cat((x2,d3),dim=1)\n",
    "#         d3 = self.Up_conv3(d3)\n",
    "\n",
    "#         d2 = self.Up2(d3)\n",
    "#         d2 = torch.cat((x1,d2),dim=1)\n",
    "#         d2 = self.Up_conv2(d2)\n",
    "\n",
    "#         d1 = self.Conv_1x1(d2)\n",
    "\n",
    "#         return d1\n",
    "\n",
    "# model = U_Net().to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R2U_Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T17:52:04.485585Z",
     "iopub.status.busy": "2024-05-14T17:52:04.485109Z",
     "iopub.status.idle": "2024-05-14T17:52:04.492817Z",
     "shell.execute_reply": "2024-05-14T17:52:04.491994Z",
     "shell.execute_reply.started": "2024-05-14T17:52:04.485560Z"
    }
   },
   "outputs": [],
   "source": [
    "# class R2U_Net(nn.Module):\n",
    "#     def __init__(self,img_ch=3,output_ch=1,t=2):\n",
    "#         super(R2U_Net,self).__init__()\n",
    "        \n",
    "#         self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "#         self.Upsample = nn.Upsample(scale_factor=2)\n",
    "\n",
    "#         self.RRCNN1 = RRCNN_block(ch_in=img_ch,ch_out=64,t=t)\n",
    "\n",
    "#         self.RRCNN2 = RRCNN_block(ch_in=64,ch_out=128,t=t)\n",
    "        \n",
    "#         self.RRCNN3 = RRCNN_block(ch_in=128,ch_out=256,t=t)\n",
    "        \n",
    "#         self.RRCNN4 = RRCNN_block(ch_in=256,ch_out=512,t=t)\n",
    "        \n",
    "#         self.RRCNN5 = RRCNN_block(ch_in=512,ch_out=1024,t=t)\n",
    "        \n",
    "\n",
    "#         self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "#         self.Up_RRCNN5 = RRCNN_block(ch_in=1024, ch_out=512,t=t)\n",
    "        \n",
    "#         self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "#         self.Up_RRCNN4 = RRCNN_block(ch_in=512, ch_out=256,t=t)\n",
    "        \n",
    "#         self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "#         self.Up_RRCNN3 = RRCNN_block(ch_in=256, ch_out=128,t=t)\n",
    "        \n",
    "#         self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "#         self.Up_RRCNN2 = RRCNN_block(ch_in=128, ch_out=64,t=t)\n",
    "\n",
    "#         self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "\n",
    "#     def forward(self,x):\n",
    "#         # encoding path\n",
    "#         x1 = self.RRCNN1(x)\n",
    "\n",
    "#         x2 = self.Maxpool(x1)\n",
    "#         x2 = self.RRCNN2(x2)\n",
    "        \n",
    "#         x3 = self.Maxpool(x2)\n",
    "#         x3 = self.RRCNN3(x3)\n",
    "\n",
    "#         x4 = self.Maxpool(x3)\n",
    "#         x4 = self.RRCNN4(x4)\n",
    "\n",
    "#         x5 = self.Maxpool(x4)\n",
    "#         x5 = self.RRCNN5(x5)\n",
    "\n",
    "#         # decoding + concat path\n",
    "#         d5 = self.Up5(x5)\n",
    "#         d5 = torch.cat((x4,d5),dim=1)\n",
    "#         d5 = self.Up_RRCNN5(d5)\n",
    "        \n",
    "#         d4 = self.Up4(d5)\n",
    "#         d4 = torch.cat((x3,d4),dim=1)\n",
    "#         d4 = self.Up_RRCNN4(d4)\n",
    "\n",
    "#         d3 = self.Up3(d4)\n",
    "#         d3 = torch.cat((x2,d3),dim=1)\n",
    "#         d3 = self.Up_RRCNN3(d3)\n",
    "\n",
    "#         d2 = self.Up2(d3)\n",
    "#         d2 = torch.cat((x1,d2),dim=1)\n",
    "#         d2 = self.Up_RRCNN2(d2)\n",
    "\n",
    "#         d1 = self.Conv_1x1(d2)\n",
    "\n",
    "#         return d1\n",
    "    \n",
    "# model = R2U_Net().to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AttU_Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T17:52:04.494321Z",
     "iopub.status.busy": "2024-05-14T17:52:04.494008Z",
     "iopub.status.idle": "2024-05-14T17:52:05.106737Z",
     "shell.execute_reply": "2024-05-14T17:52:05.105824Z",
     "shell.execute_reply.started": "2024-05-14T17:52:04.494291Z"
    }
   },
   "outputs": [],
   "source": [
    "# class AttU_Net(nn.Module):\n",
    "#     def __init__(self,img_ch=3,output_ch=1):\n",
    "#         super(AttU_Net,self).__init__()\n",
    "        \n",
    "#         self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "#         self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n",
    "#         self.Conv2 = conv_block(ch_in=64,ch_out=128)\n",
    "#         self.Conv3 = conv_block(ch_in=128,ch_out=256)\n",
    "#         self.Conv4 = conv_block(ch_in=256,ch_out=512)\n",
    "#         self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n",
    "\n",
    "#         self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "#         self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n",
    "#         self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
    "\n",
    "#         self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "#         self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n",
    "#         self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
    "        \n",
    "#         self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "#         self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n",
    "#         self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
    "        \n",
    "#         self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "#         self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n",
    "#         self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
    "\n",
    "#         self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "\n",
    "#     def forward(self,x):\n",
    "#         # encoding path\n",
    "#         x1 = self.Conv1(x)\n",
    "\n",
    "#         x2 = self.Maxpool(x1)\n",
    "#         x2 = self.Conv2(x2)\n",
    "        \n",
    "#         x3 = self.Maxpool(x2)\n",
    "#         x3 = self.Conv3(x3)\n",
    "\n",
    "#         x4 = self.Maxpool(x3)\n",
    "#         x4 = self.Conv4(x4)\n",
    "\n",
    "#         x5 = self.Maxpool(x4)\n",
    "#         x5 = self.Conv5(x5)\n",
    "\n",
    "#         # decoding + concat path\n",
    "#         d5 = self.Up5(x5)\n",
    "#         x4 = self.Att5(g=d5,x=x4)\n",
    "#         d5 = torch.cat((x4,d5),dim=1)        \n",
    "#         d5 = self.Up_conv5(d5)\n",
    "        \n",
    "#         d4 = self.Up4(d5)\n",
    "#         x3 = self.Att4(g=d4,x=x3)\n",
    "#         d4 = torch.cat((x3,d4),dim=1)\n",
    "#         d4 = self.Up_conv4(d4)\n",
    "\n",
    "#         d3 = self.Up3(d4)\n",
    "#         x2 = self.Att3(g=d3,x=x2)\n",
    "#         d3 = torch.cat((x2,d3),dim=1)\n",
    "#         d3 = self.Up_conv3(d3)\n",
    "\n",
    "#         d2 = self.Up2(d3)\n",
    "#         x1 = self.Att2(g=d2,x=x1)\n",
    "#         d2 = torch.cat((x1,d2),dim=1)\n",
    "#         d2 = self.Up_conv2(d2)\n",
    "\n",
    "#         d1 = self.Conv_1x1(d2)\n",
    "\n",
    "#         return d1\n",
    "    \n",
    "    \n",
    "# model = AttU_Net().to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R2AttU_Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T17:52:05.108446Z",
     "iopub.status.busy": "2024-05-14T17:52:05.108084Z",
     "iopub.status.idle": "2024-05-14T17:52:05.115514Z",
     "shell.execute_reply": "2024-05-14T17:52:05.114550Z",
     "shell.execute_reply.started": "2024-05-14T17:52:05.108398Z"
    }
   },
   "outputs": [],
   "source": [
    "# class R2AttU_Net(nn.Module):\n",
    "#     def __init__(self,img_ch=3,output_ch=1,t=2):\n",
    "#         super(R2AttU_Net,self).__init__()\n",
    "        \n",
    "#         self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "#         self.Upsample = nn.Upsample(scale_factor=2)\n",
    "\n",
    "#         self.RRCNN1 = RRCNN_block(ch_in=img_ch,ch_out=64,t=t)\n",
    "\n",
    "#         self.RRCNN2 = RRCNN_block(ch_in=64,ch_out=128,t=t)\n",
    "        \n",
    "#         self.RRCNN3 = RRCNN_block(ch_in=128,ch_out=256,t=t)\n",
    "        \n",
    "#         self.RRCNN4 = RRCNN_block(ch_in=256,ch_out=512,t=t)\n",
    "        \n",
    "#         self.RRCNN5 = RRCNN_block(ch_in=512,ch_out=1024,t=t)\n",
    "        \n",
    "\n",
    "#         self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "#         self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n",
    "#         self.Up_RRCNN5 = RRCNN_block(ch_in=1024, ch_out=512,t=t)\n",
    "        \n",
    "#         self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "#         self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n",
    "#         self.Up_RRCNN4 = RRCNN_block(ch_in=512, ch_out=256,t=t)\n",
    "        \n",
    "#         self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "#         self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n",
    "#         self.Up_RRCNN3 = RRCNN_block(ch_in=256, ch_out=128,t=t)\n",
    "        \n",
    "#         self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "#         self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n",
    "#         self.Up_RRCNN2 = RRCNN_block(ch_in=128, ch_out=64,t=t)\n",
    "\n",
    "#         self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "\n",
    "#     def forward(self,x):\n",
    "#         # encoding path\n",
    "#         x1 = self.RRCNN1(x)\n",
    "\n",
    "#         x2 = self.Maxpool(x1)\n",
    "#         x2 = self.RRCNN2(x2)\n",
    "        \n",
    "#         x3 = self.Maxpool(x2)\n",
    "#         x3 = self.RRCNN3(x3)\n",
    "\n",
    "#         x4 = self.Maxpool(x3)\n",
    "#         x4 = self.RRCNN4(x4)\n",
    "\n",
    "#         x5 = self.Maxpool(x4)\n",
    "#         x5 = self.RRCNN5(x5)\n",
    "\n",
    "#         # decoding + concat path\n",
    "#         d5 = self.Up5(x5)\n",
    "#         x4 = self.Att5(g=d5,x=x4)\n",
    "#         d5 = torch.cat((x4,d5),dim=1)\n",
    "#         d5 = self.Up_RRCNN5(d5)\n",
    "        \n",
    "#         d4 = self.Up4(d5)\n",
    "#         x3 = self.Att4(g=d4,x=x3)\n",
    "#         d4 = torch.cat((x3,d4),dim=1)\n",
    "#         d4 = self.Up_RRCNN4(d4)\n",
    "\n",
    "#         d3 = self.Up3(d4)\n",
    "#         x2 = self.Att3(g=d3,x=x2)\n",
    "#         d3 = torch.cat((x2,d3),dim=1)\n",
    "#         d3 = self.Up_RRCNN3(d3)\n",
    "\n",
    "#         d2 = self.Up2(d3)\n",
    "#         x1 = self.Att2(g=d2,x=x1)\n",
    "#         d2 = torch.cat((x1,d2),dim=1)\n",
    "#         d2 = self.Up_RRCNN2(d2)\n",
    "\n",
    "#         d1 = self.Conv_1x1(d2)\n",
    "\n",
    "#         return d1\n",
    "    \n",
    "# model = R2AttU_Net().to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeplabv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T08:51:32.542174Z",
     "iopub.status.busy": "2024-05-18T08:51:32.541847Z",
     "iopub.status.idle": "2024-05-18T08:51:33.737201Z",
     "shell.execute_reply": "2024-05-18T08:51:33.736269Z",
     "shell.execute_reply.started": "2024-05-18T08:51:32.542151Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation import deeplabv3_resnet50, deeplabv3_resnet101, deeplabv3_mobilenet_v3_large\n",
    "from torchvision.models.segmentation import (\n",
    "                                            DeepLabV3_ResNet50_Weights, \n",
    "                                             DeepLabV3_ResNet101_Weights, \n",
    "                                             DeepLabV3_MobileNet_V3_Large_Weights\n",
    "                                             )\n",
    "  \n",
    "#model_name == \"resnet_50\":\n",
    "#model = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
    "#transforms = DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1.transforms()\n",
    "\n",
    "#model_name == \"resnet_101\":\n",
    "model = deeplabv3_resnet101()   #weights=DeepLabV3_ResNet101_Weights.DEFAULT\n",
    "#transforms = DeepLabV3_ResNet101_Weights.COCO_WITH_VOC_LABELS_V1.transforms()\n",
    "\n",
    "#model_name == \"mobilenet\":\n",
    "#model = deeplabv3_mobilenet_v3_large(weights=DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT)\n",
    "#transforms = DeepLabV3_MobileNet_V3_Large_Weights.COCO_WITH_VOC_LABELS_V1.transforms()\n",
    "\n",
    "new_conv_layer = nn.Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
    "model.classifier[-1] = new_conv_layer\n",
    "\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T08:51:41.598021Z",
     "iopub.status.busy": "2024-05-18T08:51:41.597226Z",
     "iopub.status.idle": "2024-05-18T08:51:41.605426Z",
     "shell.execute_reply": "2024-05-18T08:51:41.604408Z",
     "shell.execute_reply.started": "2024-05-18T08:51:41.597987Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "lossfunc = BCEWithLogitsLoss()\n",
    "lr = 1e-3\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=2e-5)\n",
    "\n",
    "num_epoch = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T08:52:02.145716Z",
     "iopub.status.busy": "2024-05-18T08:52:02.145126Z",
     "iopub.status.idle": "2024-05-18T10:37:27.273562Z",
     "shell.execute_reply": "2024-05-18T10:37:27.272511Z",
     "shell.execute_reply.started": "2024-05-18T08:52:02.145688Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Start training the network...\")\n",
    "startTime = time.time()\n",
    "\n",
    "val_loss = []\n",
    "train_loss = []\n",
    "\n",
    "best_loss = math.inf\n",
    "\n",
    "for epoch in tqdm(range(num_epoch)):\n",
    "    model.train()\n",
    "    totalTrainLoss = 0\n",
    "    totalTestLoss = 0\n",
    "    # loop over the training set\n",
    "    for (i, (raw, gt)) in enumerate(train_loader):\n",
    "        (raw, gt) = (raw.to(device), gt.to(device))\n",
    "        raw = raw.to(torch.float)\n",
    "        gt = gt.to(torch.float)\n",
    "        #print(raw.shape, gt.shape)\n",
    "        \n",
    "        pred = model(raw)[\"out\"]  #only for deeplabv3\n",
    "        #pred = model(raw)\n",
    "        \n",
    "        loss = lossfunc(pred, gt)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        # add the loss to the total training loss so far\n",
    "        totalTrainLoss += loss\n",
    "        \n",
    "    train_loss.append(totalTrainLoss.detach().cpu().numpy())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # set the model in evaluation mode\n",
    "        model.eval()\n",
    "        # loop over the validation set\n",
    "        for (raw, gt) in val_loader:\n",
    "            (raw, gt) = (raw.to(device), gt.to(device))\n",
    "            raw = raw.to(torch.float)\n",
    "            gt = gt.to(torch.float)\n",
    "            \n",
    "            pred = model(raw)[\"out\"]   ##only for deeplabv3\n",
    "            #pred = model(raw)\n",
    "            \n",
    "            curr_loss = lossfunc(pred, gt)\n",
    "            totalTestLoss += curr_loss\n",
    "    val_loss.append(totalTestLoss.detach().cpu().numpy()) \n",
    "    \n",
    "    if(totalTestLoss<best_loss):\n",
    "        print(f'Saving best weight at epoch: {epoch}.......')\n",
    "        torch.save(model.state_dict(), 'model_weights.pth')    \n",
    "        best_loss = totalTestLoss\n",
    "            \n",
    "    print(f\"Train loss: {totalTrainLoss/i}, Val loss: {totalTestLoss/i}\")\n",
    "    \n",
    "    print(\"EPOCH: {}/{}\".format(epoch + 1, num_epoch))\n",
    "    \n",
    "    #print(\"Train loss: {:.6f}, Test loss: {:.4f}\".format(avgTrainLoss, avgTestLoss))\n",
    "# display the total time needed to perform the training\n",
    "endTime = time.time()\n",
    "print(\"total time taken to train the model: {:.2f}s\".format(endTime - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T10:37:27.275697Z",
     "iopub.status.busy": "2024-05-18T10:37:27.275384Z",
     "iopub.status.idle": "2024-05-18T10:37:27.920323Z",
     "shell.execute_reply": "2024-05-18T10:37:27.919441Z",
     "shell.execute_reply.started": "2024-05-18T10:37:27.275669Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data\n",
    "x = list(range(1,len(train_loss)+1))  \n",
    "plt.plot(x, train_loss, label='train')  # Plot the first line and specify its label\n",
    "plt.plot(x, val_loss, label='val')  # Plot the second line and specify its label\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train loss', 'validation loss'])\n",
    "plt.savefig('loss_curve_binary.png', dpi=300) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T10:37:27.921866Z",
     "iopub.status.busy": "2024-05-18T10:37:27.921535Z",
     "iopub.status.idle": "2024-05-18T10:37:27.937105Z",
     "shell.execute_reply": "2024-05-18T10:37:27.936106Z",
     "shell.execute_reply.started": "2024-05-18T10:37:27.921834Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy(SR,GT,threshold=0.5):\n",
    "    SR = (SR > threshold)*1\n",
    "    GT = GT == torch.max(GT)\n",
    "    corr = torch.sum(SR==GT)\n",
    "    tensor_size = SR.size(0)*SR.size(1)*SR.size(2)*SR.size(3)\n",
    "    acc = float(corr)/float(tensor_size)\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "def get_F1(SR,GT,threshold=0.5):\n",
    "    # Sensitivity == Recall\n",
    "    SE = get_sensitivity(SR,GT,threshold=threshold)\n",
    "    PC = get_precision(SR,GT,threshold=threshold)\n",
    "    \n",
    "    print(SE, PC)\n",
    "\n",
    "    F1 = 2*SE*PC/(SE+PC + 1e-6)\n",
    "\n",
    "    return F1\n",
    "\n",
    "def calculate_f1_from_masks(y_pred, y_true, threshold=0.5):\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = (y_pred.flatten() > threshold)*1\n",
    "    \n",
    "    tp = torch.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = torch.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = torch.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    \n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    \n",
    "    if(f1>0):\n",
    "        return f1.cpu().numpy()\n",
    "    else:\n",
    "        return f1\n",
    "\n",
    "\n",
    "def get_JS(SR,GT,threshold=0.5):   ##same as Jaccard index, IoU\n",
    "    # JS : Jaccard similarity\n",
    "    SR = (SR > threshold)*1\n",
    "    GT = GT == torch.max(GT)\n",
    "    \n",
    "    Inter = torch.sum((SR+GT)==2)\n",
    "    Union = torch.sum((SR+GT)>=1)\n",
    "    \n",
    "    JS = float(Inter)/(float(Union) + 1e-6)\n",
    "    \n",
    "    return JS\n",
    "\n",
    "def get_DC(SR,GT,threshold=0.5):\n",
    "    # DC : Dice Coefficient\n",
    "    SR = (SR > threshold)*1\n",
    "    GT = GT == torch.max(GT)\n",
    "\n",
    "    Inter = torch.sum((SR+GT)==2)\n",
    "    DC = float(2*Inter)/(float(torch.sum(SR)+torch.sum(GT)) + 1e-6)\n",
    "\n",
    "    return DC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T10:47:46.781173Z",
     "iopub.status.busy": "2024-05-18T10:47:46.780291Z",
     "iopub.status.idle": "2024-05-18T10:48:02.785046Z",
     "shell.execute_reply": "2024-05-18T10:48:02.784039Z",
     "shell.execute_reply.started": "2024-05-18T10:47:46.781143Z"
    }
   },
   "outputs": [],
   "source": [
    "totaltestacc = 0\n",
    "totaltestloss = 0\n",
    "totaltestJS = 0\n",
    "totaltestdice = 0\n",
    "totaltestf1 = 0\n",
    "\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    # loop over the validation set\n",
    "    for i, (raw, gt) in enumerate(test_loader):\n",
    "        (raw, gt) = (raw.to(device), gt.to(device))\n",
    "        raw = raw.to(torch.float)\n",
    "        gt = gt.to(torch.float)\n",
    "        \n",
    "        pred = model(raw)[\"out\"]  ##only for deeplabv3\n",
    "        #pred = model(raw)\n",
    "        \n",
    "        pred = torch.sigmoid(pred)\n",
    "\n",
    "        totaltestloss += lossfunc(pred, gt)\n",
    "        totaltestacc += get_accuracy(pred, gt)\n",
    "        totaltestf1 += calculate_f1_from_masks(pred, gt)\n",
    "        totaltestJS += get_JS(pred, gt, threshold=0.5)\n",
    "        totaltestdice += get_DC(pred, gt, threshold=0.5)  ##dice score and F1 are almost same\n",
    "        #print(calculate_f1_from_masks(pred, gt))\n",
    "        \n",
    "print(f\"total test loss {totaltestloss/i}, acc is {totaltestacc/i},f1 is {totaltestf1/i} dice is {totaltestdice/i}, JS is {totaltestJS/i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T10:37:44.990512Z",
     "iopub.status.busy": "2024-05-18T10:37:44.990158Z",
     "iopub.status.idle": "2024-05-18T10:37:44.996166Z",
     "shell.execute_reply": "2024-05-18T10:37:44.995231Z",
     "shell.execute_reply.started": "2024-05-18T10:37:44.990479Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('bin_scores.txt', 'w') as file:\n",
    "    file.write(f'Dice co-efficient: {totaltestdice/i}\\n')\n",
    "    file.write(f'Jaccard index: {totaltestJS/i}\\n')\n",
    "    file.write(f'Accuracy: {totaltestacc/i}\\n')\n",
    "    file.write(f'f1_score: {totaltestf1/i}\\n')\n",
    "    #file.write(f'classwise jaccard: {classwisescore}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4960812,
     "sourceId": 8349901,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4992853,
     "sourceId": 8394606,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
